---
output: html_document
editor_options: 
  chunk_output_type: inline
---

<!-- CSS options for custom title numbers styling-->
<style>
.header-section-number:after {
  content: ". ";
}
</style>

### Preliminary Set-up {.unnumbered}

::: {.callout-note collapse="true"}

#### Datasets, code availability, software, setup

##### Data

The folder containing this HTML file also has a "`data/`" folder, wherein can be found the main Excel file from which the datasets analysed here are sourced, i.e. "`raw_data_lena.xlsx`". 

<!-- The original first nine sheets have been merged into a single table and tidied in the setup code below: the resulting table has been exported in the tenth sheet. -->

##### Code availability and software

The code generating all the computations, figures, tables, etc. (only partially exposed here for clarity) can be found in the `2310-lena-analyses.qmd` file, for which the best reading software are coding Integrated Development Environments (IDE) like [RStudio](https://posit.co/download/rstudio-desktop/) or [Visual Studio Code](https://code.visualstudio.com/). The file includes detailed commentaries along with the code to ease understanding, accessibility, and potential (welcome) criticism.

This analysis was conducted in R language on [RStudio](https://posit.co/download/rstudio-desktop/). This analysis report was written with [Quarto](https://quarto.org/). 

##### Setup

Just down below is the setup code, including two essential steps: 

1. Installing the required packages for this data analysis

2. importing data into the dataframes used throughout. 

I left this (usually hidden) step here for reference of the tools used in a view of transparency for the interested reader.

```{r setup}
#| output: false
#| echo: true
#| code-summary: "Packages"

# The package `librairian` will ease the package management with the "shelf" 
# function, which automatically: 
# 1) checks if a package is installed 
# 2) installs it if need be
# 3) loads the package like the "library()" function would.
if (!require(librarian)) install.packages(librarian)
library(librarian)

# now putting packages on our library's shelves:
shelf(
  # --- essential package collections ---
  tidyverse,      # modern R ecosystem
  easystats,      # data analysis framework
  tidymodels,     # modelling framework
  
  # --- tidymodels friends
  corrr,          # correlational analyses
  tidybayes,      # bayesian inference
  multilevelmod,  # multilevel modelling with lmer and tidymodels
  
  # --- modelling
  lme4,           # mixed models
  mclust,         # mixture clustering
  rstanarm,       # bayesian models
  BayesFactor,    # BFs
  
  # --- data management
  readxl,         # importing xlsx
  openxlsx,       # exporting xlsx
  
  # --- data visualization
  # plot types and geoms
  ricardo-bion/ggradar,  # radar plots
  ggbeeswarm,            # scatter violin plots
  GGally,         # complex plots
  # layout and options
  ggpubr,         # publication plots
  patchwork,      # layout control
  rstatix,        # ggplot stat tools
  # palettes
  ggsci,          # scientific palettes
  viridis,        # colour-blind friendly palettes
  # interactive
  plotly         # interactive plots
)

theme_set(theme_bw(base_size = 14)) # global ggplot theme
set.seed(89910514) # fixing a seed for reproducibility

```

```{r importing_data}
#| echo: true
#| code-summary: "Importing data"

path <- "data/raw_data_lena.xlsx"
#_______________________________________________________________________________

# The raw data being magnificently tidy from the get-go, we only need to stack
# the successive dataframes on top of each other
df <-
  bind_rows(
    read_excel(path, sheet = "Session 1", range = "B1:V142"),
    read_excel(path, sheet = "Session 2", range = "B1:V142"),
    read_excel(path, sheet = "Session 3", range = "B1:V142"),
    read_excel(path, sheet = "Session 4", range = "B1:V142"),
    read_excel(path, sheet = "Session 5", range = "B1:V142"),
    read_excel(path, sheet = "Session 6", range = "B1:V142"),
    read_excel(path, sheet = "Session 7", range = "B1:V142"),
    read_excel(path, sheet = "Session 8", range = "B1:V142"),
    read_excel(path, sheet = "Session 9", range = "B1:V142")
  ) |> 
  # removing irrelevant columns
  select(-c(
    "date de naissance",
    age_bis, 
    genre, 
    personnages,
    "FR-Categ",
    "FR-Non categ",
    "SAM-Valence",
    "SAM-Intensité"
    )
  ) |>  
  rename(
    group     = "Groupe",
    subject   = "Pseudonyme",
    man       = "genre_bis",
    comprehension  = "histoire",
    categorization = "intrus",
    visuo_spatial = "puzzles",
    reco          = "reconnaissance",
    false_reco    = "Fausses-Reco",
    vis_spa_wm    = "mdt-visuo",
    attention     = "barrages"
  ) |>  
  mutate(
    # subject ids in lower case
    subject = tolower(subject),
    # group renaming
    group = if_else(group == "Contrôle", "control", group),
    # false_reco is reverse-coded
    false_reco = 20 - false_reco
  ) |>  
  mutate(across(c(group, subject, man:session), ~ as.factor(.x))) |> 
  # filtering out missing evaluations
  filter(
    !is.na(age) &
    !is.na(comprehension) & 
    !is.na(categorization) & 
    !is.na(visuo_spatial)
  ) |> 
  fill(everything())
```

```{r na_check}
# NA check
# df |> summarise(across(everything(), ~sum(is.na(.x))))
```

:::

:::{.callout-tip appearance="simple"}

#### Interactive figures

Many figures in this report are interactive: hover over the plots to see some of the tools available. You can select a zone to zoom on a plot, hover over bars to see details about data, select only specific groups in the legend, among many other features.

:::

# Exploratory Data Analysis

The study was conducted on 141 second grade children scattered in five very similar schools from the same district: they were therefore divided into five groups approximately following this distribution. They followed a training curriculum consisting of four different learning modalities, each repeated twice in the year.

```{r}
#| label: tbl-group_repartition
#| tbl-cap: "Number of children in each experimental group."

df |>
  group_by(group, subject) |> 
  summarise() |> 
  count() |> 
  ungroup() |> 
  rename(
    N = n,
    Group = group
  ) |>
  mutate(Group = ifelse(Group == "control", "Control", Group)) |> 
  display()
```

A distinctive feature of the study's tests is that they were modified over time to adapt to children's progression and avoid ceiling effects. Therefore, an analysis of raw scores would lead to *negative* differences between sessions, that could be interpreted as a regression of the student. These difficulty variations make it useless to compare raw scores between sessions and conditions. Consequently, to assess the level of the students, We will center the scores for each test on the average level of all children across groups ***per session***: the score of a student to a given test in a given session will thus be evaluated only *relatively* to the score of other students. In the end, each outcome variable in each session will have a mean of 0. 

```{r standardizing}
#| echo: true
#| code-summary: Standardizing per session

df_norm <- 
  df |>
  group_by(session) |> 
  mutate(across(comprehension:attention, ~as.numeric(scale(.x))))
```

## Correlations

Let's see the distributions and correlations between our various **outcomes**. The results of the Bayesian correlations between the variables are displayed in @fig-cor_matrix and the distributions in @fig-distributions.

:::{.panel-tabset}

#### Correlation between scores

```{r correlations}
#| label: fig-cor_matrix
#| fig-cap: "Correlation between the main outcomes of the study. The stars indicate the amount of evidence in favour of a correlation, as assessed by the $BF_{10}$: No star = Anecdotal evidence, * = Weak evidence, ** = Moderate evidence, *** = Extreme evidence."
#| fig-width: 10
#| fig-height: 7

df_norm |>
  ungroup() |> 
  select(comprehension:attention) |> 
  correlation(
    bayesian = TRUE,
    bayesian_test = "bf"
  ) |> 
  summary() |> 
  plot(
    labs = list(title = "")
  ) + 
  scale_fill_viridis(
    option = "D",
    # guide = NULL,
    alpha = .6,
    direction = 1,
    limits = c(-.3,.3)
  ) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.text = element_text(size = 14)
    )
```

#### Distribution of the scores

```{r distributions}
#| label: fig-distributions
#| fig-cap: "Distribution of the seven main outcomes of the study."
#| fig-width: 10
#| fig-height: 8

(df_norm |> 
  select(session, comprehension:attention) |> 
  pivot_longer(cols = comprehension:attention) |> 
  ggplot(aes(x = value, color = session, fill = session)) +
  geom_density(alpha = .4) +
  scale_color_viridis_d(name = "Session") +
  scale_fill_viridis_d(name  = "Session") +
  labs(x = "Score", y = "Density") 
  ) |> 
  facet(
    facet.by = "name",
    panel.labs = list(name = c(
      "Attention",
      "Categorization",
      "Comprehension",
      "False recognition",
      "Recognition",
      "Visuo-spatial WM",
      "Visuo-spatial test"))
    )
```

:::

As we can see, several scores are significantly correlated (although with modest effect sizes), including some of the main tests, namely *comprehension*, *categorization* and *recognition* - among others. This suggests that, beyond their specificities, these tests might reflect common (cognitive) characteristics of the participants, e.g. in this case supposedly a "general ability level" of the child. To materialize this "general" variable, we will run a **Principal Component Analysis** and see if the different scores could be "merged" into a single variable (a "component", in PCA terms).

## Principal Component Analysis {#sec-pca}

```{r pca}
#| code-summary: "Computing the PCA"
#| echo: true

# --- Principal Component Analysis ---
pca <- 
  principal_components(
    df_norm[,7:13],
    n = "max",
    sort = TRUE,
    standardize = TRUE
    ) 
```

The resulting components of this PCA are displayed in @fig-loadings and @tbl-eigenvalues.

:::{.panel-tabset}

#### PCA loadings

```{r loadings}
#| label: fig-loadings
#| fig-cap: "Loadings of each variable on the six components extracted by a PCA."
#| fig-width: 9
#| fig-height: 7

# --- Loadings ---
pca |> 
  plot() + 
  # scale_y_discrete(labels = c("OSIQ-S", "OSIQ-O", "VVIQ", "SUIS")) +
  scale_fill_viridis(alpha = .6) +
  labs(title = NULL) +
  theme(text = element_text(size = 14))
```

#### Eigenvalues / variance explained

```{r eigenvalues}
#| label: tbl-eigenvalues
#| tbl-cap: "Eigenvalues and variance explained by the six components extracted by a PCA."

# --- Eigenvalues and variance ---
pca |> 
  summary() |> 
  format(digits = 2) |> 
  display()
```

:::

As seen in @fig-cor_matrix, *comprehension*, *recognition*, *categorization* and *visuo-spatial test* scores are tightly correlated: in turn, the PCA aligned the **first component PC1** on these four variables, as shown by the coefficients of PC1 in @fig-loadings. We could interpret this first "concatenated" variable as "***reasoning***", to use a broad term at the intersection of the four tests. PC1 will be reversed to correlate positively with the four variables and ease interpretability. The **second component PC2** is highly correlated with *false recognition scores*, which indeed correlate very weakly with the other variables (see @fig-cor_matrix). Thus, PC2 aligns with this score to capture the variability brought by it. We'll keep it named "***false recognition***", although the variable deviated a bit from the original one. The **third component PC3** is correlated with *visuo-spatial working memory*, *attention*, and *false recognition*. It can be noted that, besides false recognition, this correlation (and subsequent component) between visuo-spatial WM and attention interestingly lines up with the **TBRS model**. Thus, PC3 will be named ***working memory***. 

The number of PCA components to keep as meaningful to explain the data can be assessed with the Eigenvalues and the variance explained by each of the components: as a rule of thumb, an Eigenvalue very close or superior to 1 denotes a good PCA component. In our case, only the first three components meet this criteria, as shown in @tbl-eigenvalues. These three components explain 56% of the total variance in the sample. Let's predict these new variables for each participant and add them to the data.

```{r pca_components}
#| code-summary: "Adding the predicted PCA components to the data"
#| echo: true

pca_components <- pca |> predict()

df_pca <-
  bind_cols(df_norm, pca_components[,1:3]) |> 
  mutate(
    PC1 = -c(scale(PC1)),
    PC2 = c(scale(PC2)),
    PC3 = c(scale(PC3))
    ) |> 
  rename(
    "pca_reasoning"  = PC1,
    "pca_false_reco" = PC2,
    "pca_wm"         = PC3
    )
```

Let's see how these components behave in @fig-pca_distributions and @fig-cor_pca.

:::{.panel-tabset}

#### Correlation between components and scores

```{r cor_pca}
#| label: fig-cor_pca
#| fig-cap: "Correlation between the PCA components. The stars indicate the amount of evidence in favour of a correlation, as assessed by the $BF_{10}$: No star = Anecdotal evidence, * = Weak evidence, ** = Moderate evidence, *** = Extreme evidence."
#| fig-width: 14
#| fig-height: 10

df_pca |>
  ungroup() |> 
  select(comprehension:pca_wm) |> 
  correlation(
    bayesian = TRUE,
    bayesian_test = "bf"
  ) |> 
  summary() |> 
  plot(
    labs = list(title = "")
  ) + 
  scale_fill_viridis(
    option = "D",
    # guide = NULL,
    alpha = .6,
    direction = 1,
    limits = c(-.8,.8)
  ) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.text = element_text(size = 14)
    )
```

#### Distribution of the components

```{r pca_distributions}
#| label: fig-pca_distributions
#| fig-cap: "Distribution of the three components"
#| fig-width: 12
#| fig-height: 6

(df_pca |> 
  select(session, pca_reasoning:pca_wm) |> 
  pivot_longer(cols = pca_reasoning:pca_wm) |> 
  ggplot(aes(x = value, color = session, fill = session)) +
  geom_density(alpha = .4) +
  scale_color_viridis_d(name = "Session") +
  scale_fill_viridis_d(name = "Session") +
  labs(x = "Score", y = "Density") 
  ) |> 
  facet(
    facet.by = "name",
    panel.labs = list(name = c(
      "Reasoning",
      "False recognition",
      "Working memory"))
  ) |> 
  ggplotly()
```

:::

As expected from the PCA, the three components are now completely decorrelated (bottom left corner of @fig-cor_pca) and show the relevant correlations with the initial scores mentioned above. Most of the analyses that follow could be conducted on each outcome variable individually: for the sake of simplicity (the mischievous would say *parsimony*), we will model only these three components.

## Examining trends

Let's visualize our outcome variables across conditions for each children in the groups in @fig-comprehension_per_condition and all associated tabs.

:::{.panel-tabset}

#### Comprehension

```{r plot_comprehension}
#| label: fig-comprehension_per_condition
#| fig-cap: "Comprehension standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_comprehension <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(comprehension)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = comprehension
  )) +
  geom_hline(
    yintercept = mean(df_pca$comprehension),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_comprehension,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_comprehension,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(comprehension),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(comprehension),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Comprehension score (standardized)")
) |> 
  ggplotly()
```

#### Categorization

```{r plot_categorization}
#| label: fig-categorization_per_condition
#| fig-cap: "Categorization standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_categorization <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(categorization)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = categorization
  )) +
  geom_hline(
    yintercept = mean(df_pca$categorization),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_categorization,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_categorization,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(categorization),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(categorization),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Categorization score (standardized)")
) |> 
  ggplotly()
```

#### Visuo-spatial test

```{r plot_visuo_spatial}
#| label: fig-visuo_spatial_per_condition
#| fig-cap: "Visuo-spatial test standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_visuo_spatial <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(visuo_spatial)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = visuo_spatial
  )) +
  geom_hline(
    yintercept = mean(df_pca$visuo_spatial),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_visuo_spatial,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_visuo_spatial,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(visuo_spatial),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(visuo_spatial),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Visuo-spatial test score (standardized)")
) |> 
  ggplotly()
```


#### Recognition

```{r plot_recognition}
#| label: fig-recognition_per_condition
#| fig-cap: "Recognition test standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_reco <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(reco)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = reco
  )) +
  geom_hline(
    yintercept = mean(df_pca$reco),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_reco,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_reco,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(reco),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(reco),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Recognition test score (standardized)")
) |> 
  ggplotly()
```


#### False recognition

```{r plot_false_reco}
#| label: fig-false_reco_per_condition
#| fig-cap: "False recognition test standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_false_reco <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(false_reco)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = false_reco
  )) +
  geom_hline(
    yintercept = mean(df_pca$false_reco),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_false_reco,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_false_reco,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(false_reco),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(false_reco),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "False recognition test score (standardized)")
) |> 
  ggplotly()
```



#### Visuo-spatial WM

```{r plot_visuo_spa_wm}
#| label: fig-visuo_spa_wm_per_condition
#| fig-cap: "Visuo-spatial working memory standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_vis_spa_wm <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(vis_spa_wm)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = reco
  )) +
  geom_hline(
    yintercept = mean(df_pca$vis_spa_wm),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_vis_spa_wm,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_vis_spa_wm,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(vis_spa_wm),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(vis_spa_wm),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Visuo-spatial WM score (standardized)")
) |> 
  ggplotly()
```



#### Attention

```{r plot_attention}
#| label: fig-attention_per_condition
#| fig-cap: "Attention standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_attention <-
  df_pca |> 
  filter(group != "control" & condition != 0) |> 
  group_by(group, condition) |> 
  get_summary_stats(attention)
  
(
df_pca |> 
  filter(group != "control" & condition != 0) |> 
  ggplot(aes(
    x = factor(condition, level = c("4", "3", "2", "1")),
    y = attention
  )) +
  geom_hline(
    yintercept = mean(df_pca$attention),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_attention,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_attention,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(attention),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control" & condition != 0) |> 
      group_by(condition) |> 
      get_summary_stats(attention),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Attention score (standardized)")
) |> 
  ggplotly()
```




#### Reasoning (PCA)

```{r plot_pc1}
#| label: fig-reasoning_per_condition
#| fig-cap: "Reasoning standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_reasoning <-
  df_pca |> 
  filter(group != "control") |> 
  group_by(group, condition) |> 
  get_summary_stats(pca_reasoning)
  
(
df_pca |> 
  filter(group != "control") |> 
  ggplot(aes(
    x = factor(condition, level = c("0", "4", "3", "2", "1")),
    y = pca_reasoning
  )) +
  geom_hline(
    yintercept = mean(df_pca$pca_reasoning),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_reasoning,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_reasoning,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control") |> 
      group_by(condition) |> 
      get_summary_stats(pca_reasoning),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control") |> 
      group_by(condition) |> 
      get_summary_stats(pca_reasoning),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Reasoning score (standardized, PCA variable)")
) |> 
  ggplotly()
```

#### False recognition (PCA)

```{r plot_pc2}
#| label: fig-false_reco_pc2_per_condition
#| fig-cap: "False recognition standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_pca_false_reco <-
  df_pca |> 
  filter(group != "control") |> 
  group_by(group, condition) |> 
  get_summary_stats(pca_false_reco)
  
(
df_pca |> 
  filter(group != "control") |> 
  ggplot(aes(
    x = factor(condition, level = c("0", "4", "3", "2", "1")),
    y = pca_false_reco
  )) +
  geom_hline(
    yintercept = mean(df_pca$pca_false_reco),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_pca_false_reco,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_pca_false_reco,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control") |> 
      group_by(condition) |> 
      get_summary_stats(pca_false_reco),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control") |> 
      group_by(condition) |> 
      get_summary_stats(pca_false_reco),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "False recognition score (standardized, PCA variable)")
) |> 
  ggplotly()
```

#### Working memory (PCA)

```{r plot_pc3}
#| label: fig-wm_per_condition
#| fig-cap: "Working memory standardized scores per condition and group. Colored points and dotted lines represent group means for each condition. The black dotted line is the standardized mean for every condition, i.e. 0 after the centering. Black points and lines represent condition means along with 95% confidence intervals."

df_wm <-
  df_pca |> 
  filter(group != "control") |> 
  group_by(group, condition) |> 
  get_summary_stats(pca_wm)
  
(
df_pca |> 
  filter(group != "control") |> 
  ggplot(aes(
    x = factor(condition, level = c("0", "4", "3", "2", "1")),
    y = pca_wm
  )) +
  geom_hline(
    yintercept = mean(df_pca$pca_wm),
    linetype = 2
    ) +
  geom_beeswarm(aes(
    group = group,
    color = group
    ),
    alpha = .4
  ) +
  geom_line(
    data = df_wm,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group
      ),
    linetype = 3
  ) +
  geom_point(
    data = df_wm,
    aes(
      x = condition,
      y = mean,
      group = group,
      color = group)
  ) +
  geom_pointrange(
    data = df_pca |> 
      filter(group != "control") |> 
      group_by(condition) |> 
      get_summary_stats(pca_wm),
    aes(
      x = condition,
      y = mean,
      ymin = mean - ci,
      ymax = mean + ci
      ),
    color = "black",
    size = 2
  ) +
  geom_line(
    data = df_pca |> 
      filter(group != "control") |> 
      group_by(condition) |> 
      get_summary_stats(pca_wm),
    aes(
      x = condition,
      y = mean,
      group = 1
      ),
    color = "black",
    size = 1
  ) +
  coord_cartesian(ylim = c(-2,2)) +
  scale_color_viridis_d(name = "Group") +
  labs(x = "Condition", y = "Working memory score (standardized, PCA variable)")
) |> 
  ggplotly()
```

:::

# Inferential analysis {#sec-inferential}

## Model description

### Research question and variables

Our analysis aims at answering the following question: do the outdoor activities and sensory training improve the children's learning abilities?

### Potential models




















```{r ggplot_session_effect}
# (df |> 
#   ungroup() |> 
#   group_by(subject, session) |> 
#   summarize(mean = mean(reco)) |> 
#   ungroup() |> 
#   ggplot(aes(
#     x = session, 
#     y = mean,
#     group = subject,
#     color = subject
#     )) +
#   geom_line() +
#   geom_point() +
#   scale_color_viridis_d()
#   ) |> 
#   ggplotly()
```

```{r ggplot_conditions}
# (df |>
#   group_by(session) |> 
#   standardize(comprehension:attention) |> 
#   ungroup() |> 
#   group_by(condition, session) |> 
#   summarize(mean = mean(reco)) |>
#   filter(condition != 0) |>
#   ggplot(aes(
#     x = session, 
#     y = mean,
#     group = condition,
#     color = condition)) +
#   geom_line() +
#   geom_point() +
#   scale_color_viridis_d()
#   ) |> 
#   ggplotly()
```

```{r ggplot_groups}
# (df |>
#   group_by(session) |> 
#   standardize(comprehension:attention) |> 
#   ungroup() |> 
#   group_by(group, session) |> 
#   summarize(mean = mean(reco)) |>
#   ggplot(aes(
#     x = session, 
#     y = mean,
#     group = group,
#     color = group)) +
#   geom_line() +
#   geom_point() +
#   scale_color_viridis_d()
#   ) |> 
#   ggplotly()
```

```{r ggplot_vs_control}
# (df |>
#   group_by(session) |>
#   standardize(comprehension:attention) |>
#   ungroup() |>
#   mutate(
#     group_expe = if_else(group != "control", "expe", group)
#   ) |>
#   select(group, group_expe, everything()) |>
#   group_by(group_expe, session) |>
#   summarize(mean = mean(comprehension)) |>
#   ggplot(aes(
#     x = session,
#     y = mean,
#     group = group_expe,
#     color = group_expe)) +
#   geom_line() +
#   geom_point() +
#   geom_smooth(alpha = .1, level = .5, span = .85) +
#   scale_color_viridis_d()
#   ) |>
#   ggplotly()
```









<!-- old code -->
```{r recipe}
#_______________________________________________________________________________
# # Doesn't seem to work for some reason
# recipe_model <-
#   df_norm |>
#   recipe() |>
#   update_role(
#     comprehension,
#     categorization,
#     visuo_spatial,
#     reco,
#     vis_spa_wm,
#     attention,
#     new_role = "outcome"
#   ) |>
#   update_role(
#     session,
#     condition,
#     age,
#     new_role = "predictor"
#   ) |>
#   update_role(
#     subject,
#     group,
#     new_role = "group"
#   ) |>
#   step_BoxCox(comprehension)
# 
# recipe_model |>
#   prep() |>
#   bake(df_norm)
```









